View(Cocacoladata)
Q1 <-  ifelse(grepl("Q1",Cocacola$Quarter),'1','0')
Q2 <-  ifelse(grepl("Q2",Cocacola$Quarter),'1','0')
Q3 <-  ifelse(grepl("Q3",Cocacola$Quarter),'1','0')
Q4 <-  ifelse(grepl("Q4",Cocacola$Quarter),'1','0')
#Creating 12 dummy variables
CocacolaData<-cbind(Cocacola,Q1,Q2,Q3,Q4)
View(CocacolaData)
colnames(CocacolaData)
Cocacoladata["t"]<- 1:42
View(Cocacoladata)
View(CocacolaData)
colnames(CocacolaData)
CocacolaData["t"]<- 1:42
View(CocacoladData)
View(CocacolaData)
CocacolaData["log_Sales"]<-log(CocacolaData["Sales"])
CocacolaData["t_square"]<-CocacolaData["t"]*CocacolaData["t"]
attach(CocacolaData)
View(CocacolaData)
View(amts)
train
train<-CocacolaData[1:38,]
test<-CocacolaData[39:42,]
train
########################### LINEAR MODEL #############################
linear_model<-lm(Sales~t,data=train)
summary(linear_model) ###Multiple R-squared:0.7829, Adjusted R-squared:0.7801
linear_pred<-data.frame(predict(linear_model,interval='predict',newdata =test))
View(linear_pred)
rmse_linear<-sqrt(mean((test$Sales-linear_pred$fit)^2,na.rm = T))
rmse_linear # 47.54262
######################### Exponential #################################
expo_model<-lm(log_Sales~t,data=train)
summary(expo_model) ####Multiple R-squared:0.8181, Adjusted R-squared:0.8158
expo_pred<-data.frame(predict(expo_model,interval='predict',newdata=test))
View(expo_pred)
rmse_expo<-sqrt(mean((test$Sales-exp(expo_pred$fit))^2,na.rm = T))
rmse_expo  # 43.79374
######################### Quadratic ####################################
Quad_model<-lm(Sales~t+t_square,data=train)
summary(Quad_model) ####Multiple R-squared:0.792, Adjusted R-squared:0.7866
Quad_pred<-data.frame(predict(Quad_model,interval='predict',newdata=test))
View(Quad_pred)
rmse_Quad  # 43.6544
rmse_expo  #466.248
Quad_pred<-data.frame(predict(Quad_model,interval='predict',newdata=test))
View(Quad_pred)
rmse_Quad<-sqrt(mean((test$Sales-Quad_pred$fit)^2,na.rm=T))
rmse_Quad  # 43.6544
######################### Additive Seasonality #########################
sea_add_model<-lm(Sales~Q1+Q2+Q3+Q4,data=train)
summary(sea_add_model) ###Multiple R-squared:0.2117, Adjusted R-squared:0.08423
sea_add_pred<-data.frame(predict(sea_add_model,newdata=test,interval='predict'))
rmse_sea_add<-sqrt(mean((test$Sales-sea_add_pred$fit)^2,na.rm = T))
rmse_sea_add # 129.2655
Add_sea_Linear_model<-lm(Passengers~t+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov,data=train)
summary(Add_sea_Linear_model)
######################## Additive Seasonality with Linear #################
Add_sea_Linear_model<-lm(Sales~t+Q1+Q2+Q3+Q4,data=train)
summary(Add_sea_Linear_model) ###Multiple R-squared:0.9533, Adjusted R-squared:0.9449
Add_sea_Linear_pred<-data.frame(predict(Add_sea_Linear_model,interval='predict',newdata=test))
rmse_Add_sea_Linear<-sqrt(mean((test$Sales-Add_sea_Linear_pred$fit)^2,na.rm=T))
rmse_Add_sea_Linear# 33.04571
######################## Additive Seasonality with Quadratic #################
Add_sea_Quad_model<-lm(Sales~t+t_square+Q1+Q2+Q3+Q4,data=train)
summary(Add_sea_Quad_model) ####Multiple R-squared:0.9572 , Adjusted R-squared:0.9488
Add_sea_Quad_pred<-data.frame(predict(Add_sea_Quad_model,interval='predict',newdata=test))
rmse_Add_sea_Quad<-sqrt(mean((test$Sales-Add_sea_Quad_pred$fit)^2,na.rm=T))
rmse_Add_sea_Quad # 23.91098
######################## Multiplicative Seasonality Linear trend ###########
multi_sea_model<-lm(log_Sales~Q1+Q2+Q3+Q4,data = train)
summary(multi_sea_model) ###Multiple R-squared: 0.9743, Adjusted R-squared: 0.9696
multi_sea_pred<-data.frame(predict(multi_sea_model,newdata=test,interval='predict'))
rmse_multi_sea<-sqrt(mean((test$Sales-exp(multi_sea_pred$fit))^2,na.rm = T))
rmse_multi_sea #135.3265
multi_add_sea_pred<-data.frame(predict(multi_add_sea_model,newdata=test,interval='predict'))
######################## Multiplicative Seasonality Linear trend ###########
multi_add_sea_model<-lm(log_Sales~t+Q1+Q2+Q3+Q4,data = train)
summary(multi_add_sea_model) ###Multiple R-squared: 0.9102, Adjusted R-squared: 0.8986
multi_add_sea_pred<-data.frame(predict(multi_add_sea_model,newdata=test,interval='predict'))
multi_add_sea_pred<-data.frame(predict(multi_add_sea_model,newdata=test,interval='predict'))
rmse_multi_add_sea<-sqrt(mean((test$Sales-exp(multi_add_sea_pred$fit))^2,na.rm = T))
######################## Multiplicative Seasonality Quadratic trend ###########
multi_sea_quad_model<-lm(log_Passengers~t+t_square+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov,data = train)
rmse_multi_add_sea#9.469
######################## Multiplicative Seasonality Quadratic trend ###########
multi_quad_sea_model<-lm(log_Sales~t+t_square+Q1+Q2+Q3+Q4,data = train)
multi_quad_sea_model<-lm(log_Sales~t+t_square+Q1+Q2+Q3+Q4,data = train)
summary(multi_quad_sea_model) ###Multiple R-squared: 0.9216, Adjusted R-squared: 0.9121
multi_quad_sea_pred<-data.frame(predict(multi_quad_sea_model,newdata=test,interval='predict'))
rmse_multi_quad_sea<-sqrt(mean((test$Sales-exp(multi_quad_sea_pred$fit))^2,na.rm = T))
rmse_multi_quad_sea#225.5244 #23.08635
############################ Preparing table on model and it's RMSE values
table_rmse<-data.frame(c("rmse_linear","rmse_expo","rmse_Quad","rmse_sea_add","rmse_Add_sea_Quad","rmse_multi_sea","rmse_multi_add_sea","rmse_multi_quad_sea"),c(rmse_linear,rmse_expo,rmse_Quad,rmse_sea_add,rmse_Add_sea_Quad,rmse_multi_sea,rmse_multi_add_sea,rmse_multi_quad_sea))
View(table_rmse)
colnames(table_rmse)<-c("model","RMSE")
View(table_rmse)
View(table_rmse)
View(table_rmse)
# Multiplicative seasonality with Linear has least RMSE value
new_model<-lm(log_Sales~t+Q1+Q2+Q3+Q4,data=CocacolaData)
new_model_pred<-data.frame(predict(new_model,newdata=CocacolaData,interval='predict'))
new_model_fin <- new_model$fitted.values
View(new_model_fin)
Quarter <- as.data.frame(CocacolaData$Quarter)
Final <- as.data.frame(cbind(Quarter,CocacolaData$Sales,new_model_fin))
colnames(Final) <-c("Quarter","Sales","New_Pred_Value")
plot(Final$Sales,main = "ActualGraph", xlab="Sales(Actual)", ylab="Quarter",
col.axis="blue",type="o")
plot(Final$New_Pred_Value, main = "PredictedGraph", xlab="Sales(Predicted)", ylab="Quarter",
col.axis="Green",type="s")
View(Final)
resid <- residuals(new_model)
resid[1:10]
windows()
acf(resid,lag.max = 10)
# By principal of parcimony we will consider lag - 1  as we have so
# many significant lags
# Building Autoregressive model on residuals consider lag-1
k <- arima(resid, order=c(1,0,0))
str(k)
View(data.frame(res=resid,newresid=k$residuals))
acf(k$residuals,lag.max = 15)
pred_res<- predict(arima(k$residuals,order=c(1,0,0)),n.ahead = 16)
str(pred_res)
pred_res$pred
acf(k$residuals)
write.csv(Cocacoladata,file="Cocacoladata.csv",col.names = F,row.names = F)
getwd()
test_data<-read_excel("C:\\Users\\sanu\\Downloads\\Desktop\\Documents\\Excelr\\Forecasting\\CocaCola_Sales_Rawdata.xlsx",1)
View(test_data)
test_data<-as.data.frame(test_data)
pred_new<-data.frame(predict(new_model,newdata=test,interval = 'predict'))
View(pred_new)
pred_new$fit <- pred_new$fit + pred_res$pred
pred_res<- predict(arima(k$residuals,order=c(1,0,0)),n.ahead = 4)
pred_new$fit <- pred_new$fit + pred_res$pred
View(pred_new)
# Converting data into time series object
amts<-ts(Airline$Passengers,frequency = 12,start=c(86))
View(amts)
# dividing entire data into training and testing data
train<-amts[1:38]
test<-amts[39:42] # Considering only 4 Quarters of data for testing because data itself is Quarterly
# dividing entire data into training and testing data
train<-amts[1:80]
test<-amts[81:96] # Considering only 4 Quarters of data for testing because data itself is Quarterly
# converting time series object
train<-ts(train,frequency = 12)
test<-ts(test,frequency = 12)
# Plotting time series data
plot(amts) # Visualization shows that it has level, trend, seasonality => Additive seasonality
#### USING HoltWinters function ################
# Optimum values
# with alpha = 0.2 which is default value
# Assuming time series data has only level parameter
hw_a<-HoltWinters(train,alpha = 0.2,beta = F,gamma = F)
hw_a  ####Coefficients(a) - 4020.406
hwa_pred<-data.frame(predict(hw_a,n.ahead=12))
hwa_pred
hwa_pred<-data.frame(predict(hw_a,n.ahead=12))
# By looking at the plot the forecasted values are not showing any characters of train data
plot(forecast(hw_a,h=12))
hwa_mape<-MAPE(hwa_pred$fit,test)*100   ###16.12634
pred_res<- predict(arima(k$residuals,order=c(1,0,0)),n.ahead = 12)
pred_new$fit <- pred_new$fit + pred_res$pred
View(pred_new)
hwa_mape<-MAPE(hwa_pred$fit,test)*100   ###16.12634
# By looking at the plot the forecasted values are not showing any characters of train data
plot(forecast(hw_a,h=12))
hwa_mape<-MAPE(hwa_pred$fit,test)*100   ###16.12634
hwa_pred$fit
test
# dividing entire data into training and testing data
train<-amts[1:84]
test<-amts[85:96]
train<-Airlinedata[1:84,]
test<-Airlinedata[85:96,]
########################### LINEAR MODEL #############################
linear_model<-lm(Passengers~t,data=train)
summary(linear_model) ###Multiple R-squared:0.7829, Adjusted R-squared:0.7801
linear_pred<-data.frame(predict(linear_model,interval='predict',newdata =test))
linear_pred<-data.frame(predict(linear_model,interval='predict',newdata =test))
rmse_linear<-sqrt(mean((test$Passengers-linear_pred$fit)^2,na.rm = T))
rmse_linear # 47.54262
######################### Exponential #################################
expo_model<-lm(log_Passengers~t,data=train)
summary(expo_model) ####Multiple R-squared:0.8181, Adjusted R-squared:0.8158
expo_pred<-data.frame(predict(expo_model,interval='predict',newdata=test))
rmse_expo<-sqrt(mean((test$Passengers-exp(expo_pred$fit))^2,na.rm = T))
rmse_expo # 43.79374
######################### Quadratic ####################################
Quad_model<-lm(Passengers~t+t_square,data=train)
summary(Quad_model)  ####Multiple R-squared:0.792, Adjusted R-squared:0.7866
Quad_pred<-data.frame(predict(Quad_model,interval='predict',newdata=test))
rmse_Quad<-sqrt(mean((test$Passengers-Quad_pred$fit)^2,na.rm=T))
rmse_Quad # 43.6544
######################### Additive Seasonality #########################
sea_add_model<-lm(Passengers~Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov,data=train)
summary(sea_add_model) ###Multiple R-squared:0.2117, Adjusted R-squared:0.08423
sea_add_pred<-data.frame(predict(sea_add_model,newdata=test,interval='predict'))
rmse_sea_add<-sqrt(mean((test$Passengers-sea_add_pred$fit)^2,na.rm = T))
rmse_sea_add # 129.2655
######################## Additive Seasonality with Linear #################
Add_sea_Linear_model<-lm(Passengers~t+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov,data=train)
summary(Add_sea_Linear_model) ###Multiple R-squared:0.9533, Adjusted R-squared:0.9449
Add_sea_Linear_pred<-data.frame(predict(Add_sea_Linear_model,interval='predict',newdata=test))
rmse_Add_sea_Linear<-sqrt(mean((test$Passengers-Add_sea_Linear_pred$fit)^2,na.rm=T))
rmse_Add_sea_Linear # 33.04571
######################## Additive Seasonality with Quadratic #################
Add_sea_Quad_model<-lm(Passengers~t+t_square+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov,data=train)
Add_sea_Quad_pred<-data.frame(predict(Add_sea_Quad_model,interval='predict',newdata=test))
rmse_Add_sea_Quad<-sqrt(mean((test$Passengers-Add_sea_Quad_pred$fit)^2,na.rm=T))
rmse_Add_sea_Quad # 23.91098
######################## Multiplicative Seasonality #########################
multi_sea_model<-lm(log_Passengers~Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov,data = train)
multi_sea_pred<-data.frame(predict(multi_sea_model,newdata=test,interval='predict'))
rmse_multi_sea<-sqrt(mean((test$Passengers-exp(multi_sea_pred$fit))^2,na.rm = T))
rmse_multi_sea #135.3265
######################## Multiplicative Seasonality Linear trend ###########
multi_add_sea_model<-lm(log_Passengers~t+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov,data = train)
multi_add_sea_pred<-data.frame(predict(multi_add_sea_model,newdata=test,interval='predict'))
summary(multi_add_sea_model) ###Multiple R-squared: 0.9743, Adjusted R-squared: 0.9696
multi_add_sea_pred<-data.frame(predict(multi_add_sea_model,newdata=test,interval='predict'))
rmse_multi_add_sea<-sqrt(mean((test$Passengers-exp(multi_add_sea_pred$fit))^2,na.rm = T))
rmse_multi_add_sea #9.469
######################## Multiplicative Seasonality Quadratic trend ###########
multi_sea_quad_model<-lm(log_Passengers~t+t_square+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov,data = train)
summary(multi_sea_quad_model) ###Multiple R-squared: 0.9766, Adjusted R-squared: 0.972
multi_sea_quad_pred<-data.frame(predict(multi_sea_quad_model,newdata=test,interval='predict'))
rmse_multi_sea_quad<-sqrt(mean((test$Passengers-exp(multi_sea_quad_pred$fit))^2,na.rm = T))
rmse_multi_sea_quad #23.08635
############################ Preparing table on model and it's RMSE values
table_rmse<-data.frame(c("rmse_linear","rmse_expo","rmse_Quad","rmse_sea_add","rmse_Add_sea_Quad","rmse_multi_sea","rmse_multi_add_sea","rmse_multi_sea_quad"),c(rmse_linear,rmse_expo,rmse_Quad,rmse_sea_add,rmse_Add_sea_Quad,rmse_multi_sea,rmse_multi_add_sea,rmse_multi_sea_quad))
View(table_rmse)
colnames(table_rmse)<-c("model","RMSE")
# Multiplicative seasonality with Linear has least RMSE value
new_model <- lm(log_Passengers~t+Jan+Feb+Mar+Apr+May+Jun+Jul+Aug+Sep+Oct+Nov,data=train)
resid <- residuals(new_model)
resid[1:10]
acf(resid,lag.max = 10)
# By principal of parcimony we will consider lag - 1  as we have so
# many significant lags
# Building Autoregressive model on residuals consider lag-1
k <- arima(resid, order=c(1,0,0))
acf(k$residuals,lag.max = 15)
str(pred_res)
pred_res$pred
acf(k$residuals)
test_data<-as.data.frame(test_data)
pred_new<-data.frame(predict(new_model,newdata=test,interval = 'predict'))
pred_new$fit <- pred_new$fit + pred_res$pred
View(pred_new)
# Converting data into time series object
amts<-ts(Airline$Passengers,frequency = 12,start=c(86))
# dividing entire data into training and testing data
train<-amts[1:84]
test<-amts[85:96]
# converting time series object
train<-ts(train,frequency = 12)
test<-ts(test,frequency = 12)
# Plotting time series data
plot(amts) # Visualization shows that it has level, trend, seasonality => Additive seasonality
#### USING HoltWinters function ################
# Optimum values
# with alpha = 0.2 which is default value
# Assuming time series data has only level parameter
hw_a<-HoltWinters(train,alpha = 0.2,beta = F,gamma = F)
hw_a  ####Coefficients-297.4342
hwa_pred<-data.frame(predict(hw_a,n.ahead=12))
# By looking at the plot the forecasted values are not showing any characters of train data
plot(forecast(hw_a,h=12))
hwa_mape<-MAPE(hwa_pred$fit,test)*100   ###16.12634
hwa_mape
# Now take alpha = 0.2, beta = 0.1
# Assuming time series data has level and trend parameter
hw_ab<-HoltWinters(train,alpha = 0.2,beta = 0.1,gamma = F)
hw_ab  #####Coefficients:- a - 4304.53578, b- 89.43012
hwab_pred<-data.frame(predict(hw_ab,n.ahead = 12))
# by looking at the plot the forecasted values are still missing some characters exhibited by train data
plot(forecast(hw_ab,h=12))
hwab_mape<-MAPE(hwab_pred$fit,test)*100  ###8.928086
hwab_mape
# Now assuming alpha = 0.2, beta = 0.1, gamma = 0.1
# Assuming time series data has level,trend and seasonality
hw_abg<-HoltWinters(train,alpha = 0.2,beta = 0.1,gamma = 0.1)
hw_abg
hwabg_pred<-data.frame(predict(hw_abg,n.ahead = 4))
# by looking at the plot the characters of forecasted values are closely following historical data
plot(forecast(hw_abg,h=4))
hwabg_mape<-MAPE(hwabg_pred$fit,test)*100 ###3.549841
hwabg_pred<-data.frame(predict(hw_abg,n.ahead = 12))
hwabg_mape<-MAPE(hwabg_pred$fit,test)*100 ###3.549841
hwabg_mape
# With out optimum values - Keep only alpha
hw_na<-HoltWinters(train,beta = F,gamma = F)
hw_na
hw_na
hwna_pred<-data.frame(predict(hw_na,n.ahead = 12))
hwna_pred  ###Coefficients:-4456.709 , alpha:0.502
plot(forecast(hw_na,h=4))
hwna_mape<-MAPE(hwna_pred$fit,test)*100  #####9.093032
hwna_mape
###Keep alpha and beta
hw_nab<-HoltWinters(train,gamma=F)
hw_nab #### alpha - 0.5747386, beta - 0.3105725, Coefficients:- 4581.1447, 182.7749
hwnab_pred<-data.frame(predict(hw_nab,n.ahead=12))
hwnab_pred
plot(forecast(hw_nab,h=4))
hwnab_mape<-MAPE(hwnab_pred$fit,test)*100  ###8.62752
hwnab_mape
####Keep alpha,beta and gamma
hw_nabg<-HoltWinters(train)
hw_nabg ###alpha - 0.3784328, beta-0.2526015, gamma-0.8897278, Coefficients:-a-4200.72210,
hwnabg_pred<-data.frame(predict(hw_nabg,n.ahead =4))
hwnabg_pred<-data.frame(predict(hw_nabg,n.ahead=12))
hwnabg_pred
hwnabg_mape<-MAPE(hwnabg_pred$fit,test)*100  ###2.397211
hwnabg_mape
############################## STOP HERE ###############################
df_mape<-data.frame(c("hwa_mape","hwab_mape","hwabg_mape","hwna_mape","hwnab_mape","hwnabg_mape"),c(hwa_mape,hwab_mape,hwabg_mape,hwna_mape,hwnab_mape,hwnabg_mape))
colnames(df_mape)<-c("MAPE","VALUES")
View(df_mape)
# Based on the MAPE value who choose holts winter exponential tecnique which assumes the time series
# Data level, trend, seasonality characters with default values of alpha, beta and gamma
new_model <- HoltWinters(amts)
new_model
plot(forecast(new_model,n.ahead=12))
# Forecasted values for the next 4 quarters
forecast_new <- data.frame(predict(new_model,n.ahead=12))
########################################################################
############## Now use ses,holt,hw functions ##########################
# Optimum values
# with alpha = 0.2
# Simple Exponential smoothing
ses_a<-ses(train,alpha = 0.2)
ses_a
sesa_pred<-data.frame(predict(ses_a,h=12))
plot(forecast(ses_a,n.ahead=4))
sesa_mape<-MAPE(sesa_pred$Point.Forecast,test)*100   ####16.1243
plot(forecast(ses_a,n.ahead=12))
sesa_mape<-MAPE(sesa_pred$Point.Forecast,test)*100   ####16.1243
sesa_pred<-data.frame(predict(ses_a,h=12))
plot(forecast(ses_a,n.ahead=12))
sesa_mape<-MAPE(sesa_pred$Point.Forecast,test)*100   ####16.1243
# dividing entire data into training and testing data
train<-amts[1:84]
test<-amts[85:96]
# converting time series object
train<-ts(train,frequency = 12)
test<-ts(test,frequency = 12)
sesa_mape<-MAPE(sesa_pred$Point.Forecast,test)*100   ####16.1243
# Consider alpha = 0.2, beta = 0.1
holt_ab<-holt(train,alpha = 0.2,beta = 0.1)
holt_ab
holtab_pred<-data.frame(predict(holt_ab,h=12))
holtab_mape<-MAPE(holtab_pred$Point.Forecast,test)*100  ###8.498967
holtab_pred$Point.Forecast
holtab_pred
# Converting data into time series object
amts<-ts(Airline$Passengers,frequency = 12,start=c(86))
View(amts)
# dividing entire data into training and testing data
train<-amts[1:84]
test<-amts[85:96]
# converting time series object
train<-ts(train,frequency = 12)
test<-ts(test,frequency = 12)
# Plotting time series data
plot(amts) # Visualization shows that it has level, trend, seasonality => Additive seasonality
hwa_mape<-MAPE(hwa_pred$fit,test)*100   ###17.2363
hwa_mape
########################################################################
############## Now use ses,holt,hw functions ##########################
# Optimum values
# with alpha = 0.2
# Simple Exponential smoothing
ses_a<-ses(train,alpha = 0.2)
ses_a
sesa_pred<-data.frame(predict(ses_a,h=12))
sesa_mape<-MAPE(sesa_pred$Point.Forecast,test)*100   ####16.1243
test
sesa_pred<-data.frame(predict(ses_a,h=12))
sesa_pred<-data.frame(predict(ses_a,h=8))
sesa_mape<-MAPE(sesa_pred$Point.Forecast,test)*100   ####16.1243
sesa_pred<-data.frame(predict(ses_a,h=9))
sesa_pred<-data.frame(predict(ses_a,h=11))
sesa_pred<-data.frame(predict(ses_a,h=10))
########################################################################
############## Now use ses,holt,hw functions ##########################
# Optimum values
# with alpha = 0.2
# Simple Exponential smoothing
train<-Airline[1:86,]
test<-Airline[87:96,]
ses_a<-ses(train,alpha = 0.2)
# dividing entire data into training and testing data
train<-amts[1:84]
test<-amts[85:96]
sesa_pred<-data.frame(predict(ses_a,h=10))
plot(forecast(ses_a,n.ahead=12))
sesa_mape<-MAPE(sesa_pred$Point.Forecast,test)*100   ####16.1243
# Consider alpha = 0.2, beta = 0.1
holt_ab<-holt(train,alpha = 0.2,beta = 0.1)
holtab_pred<-data.frame(predict(holt_ab,h=12))
sesa_pred<-data.frame(predict(ses_a,h=10))
sesa_mape<-MAPE(sesa_pred$Point.Forecast,test)*100   ####16.1243
plot(forecast(ses_a,n.ahead=10))
sesa_mape<-MAPE(sesa_pred$Point.Forecast,test)*100   ####16.1243
# dividing entire data into training and testing data
train<-amts[1:86]
test<-amts[87:96]
# converting time series object
train<-ts(train,frequency = 10)
test<-ts(test,frequency = 10)
#### USING HoltWinters function ################
# Optimum values
# with alpha = 0.2 which is default value
# Assuming time series data has only level parameter
hw_a<-HoltWinters(train,alpha = 0.2,beta = F,gamma = F)
hwa_pred<-data.frame(predict(hw_a,n.ahead=10))
hwa_mape<-MAPE(hwa_pred$fit,test)*100   ###17.2363
hwa_mape
# Now take alpha = 0.2, beta = 0.1
# Assuming time series data has level and trend parameter
hw_ab<-HoltWinters(train,alpha = 0.2,beta = 0.1,gamma = F)
hw_ab  #####Coefficients:- a - 297.095902, b- 2.763364
hwab_pred<-data.frame(predict(hw_ab,n.ahead = 10))
hwab_mape<-MAPE(hwab_pred$fit,test)*100  ###  11.55496
hwab_mape
# Now assuming alpha = 0.2, beta = 0.1, gamma = 0.1
# Assuming time series data has level,trend and seasonality
hw_abg<-HoltWinters(train,alpha = 0.2,beta = 0.1,gamma = 0.1)
hwabg_pred<-data.frame(predict(hw_abg,n.ahead = 10))
hwabg_mape<-MAPE(hwabg_pred$fit,test)*100 ###6.5525
hwabg_mape
# With out optimum values - Keep only alpha
hw_na<-HoltWinters(train,beta = F,gamma = F)
hwna_pred<-data.frame(predict(hw_na,n.ahead = 10))
hwna_mape<-MAPE(hwna_pred$fit,test)*100  ##### 18.55599
hwna_mape
###Keep alpha and beta
hw_nab<-HoltWinters(train,gamma=F)
hwnab_pred<-data.frame(predict(hw_nab,n.ahead=10))
hwnab_mape<-MAPE(hwnab_pred$fit,test)*100  ### 13.10429
hwnab_mape
####Keep alpha,beta and gamma
hw_nabg<-HoltWinters(train)
hwnabg_pred<-data.frame(predict(hw_nabg,n.ahead=10))
hwnabg_mape<-MAPE(hwnabg_pred$fit,test)*100  ### 1.730844
hwnabg_mape
############################## STOP HERE ###############################
df_mape<-data.frame(c("hwa_mape","hwab_mape","hwabg_mape","hwna_mape","hwnab_mape","hwnabg_mape"),c
(hwa_mape,hwab_mape,hwabg_mape,hwna_mape,hwnab_mape,hwnabg_mape))
colnames(df_mape)<-c("MAPE","VALUES")
View(df_mape)
# Based on the MAPE value who choose holts winter exponential tecnique which assumes the
##time series
# Data level, trend, seasonality characters with default values of alpha, beta and gamma
new_model <- HoltWinters(amts,alpha = 0.2,beta = 0.1,gamma = F)
new_model
# Forecasted values for the next 10 months
forecast_new <- data.frame(predict(new_model,n.ahead=10))
########################################################################
############## Now use ses,holt,hw functions ##########################
# Optimum values
# with alpha = 0.2
# Simple Exponential smoothing
ses_a<-ses(train,alpha = 0.2)
sesa_pred<-data.frame(predict(ses_a,h=10))
plot(forecast(ses_a,n.ahead=10))
sesa_mape<-MAPE(sesa_pred$Point.Forecast,test)*100   ####16.1243
sesa_mape
# Consider alpha = 0.2, beta = 0.1
holt_ab<-holt(train,alpha = 0.2,beta = 0.1)
holtab_pred<-data.frame(predict(holt_ab,h=10))
plot(forecast(holt_ab,h=10))
holtab_mape<-MAPE(holtab_pred$Point.Forecast,test)*100  ###8.498967
holtab_mape
# with alpha = 0.2, beta = 0.1, gamma = 0.1
hw_abg_new<-hw(train,alpha = 0.2,beta = 0.1,gamma = 0.1)
hwabg_pred_new<-data.frame(predict(hw_abg_new,h = 10))
hwabg_mape_new<-MAPE(hwabg_pred_new$Point.Forecast,test)*100  ####4.409854
hwabg_mape_new
# With out optimum values
# Lets check simple exponential method
ses_na<-ses(train,alpha=NULL)
sesna_pred<-data.frame(predict(ses_na,h = 10))
sesna_mape<-MAPE(sesna_pred$Point.Forecast,test)*100  ###9.132635
sesna_mape
# Check Holts winter method
holt_nab<-holt(train,alpha = NULL,beta = NULL)
holtnab_pred<-data.frame(predict(holt_nab,h=10))
plot(forecast(holt_nab,h=10))
holtnab_mape<-MAPE(holtnab_pred$Point.Forecast,test)*100  ####8.927388
holtnab_mape
# Holts winter Exponential method
hw_nabg_new<-hw(train,alpha=NULL,beta=NULL,gamma = NULL)
hwnabg_pred_new<-data.frame(predict(hw_nabg_new,h=10))
hwnabg_mape_new<-MAPE(hwnabg_pred_new$Point.Forecast,test)*100 ### 3.826562
hwnabg_mape_new
df_mapes_new<-data.frame(c("sesa_mape","holtab_mape","hwabg_mape_new","sesna_mape","holtnab_mape","hwnabg_mape_new
"),c(sesa_mape,holtab_mape,hwabg_mape_new,sesna_mape,holtnab_mape,hwnabg_mape_new))
colnames(df_mapes_new)<-c("MAPE","VALUE")
View(df_mapes_new)
# Based on the MAPE value who choose holts winter exponential tecnique which assumes the
###time series
# Data level, trend, seasonality characters
new_model <- holt(amts,alpha = NULL,beta = NULL)
# Forecasted values for the next 10 months
forecast_new <- data.frame(predict(new_model,h=10))
