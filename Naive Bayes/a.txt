##########Using Bagging
library(naivebayes)
library(adabag)
library(mlbench)
if (bag == TRUE) { 
  k <- 1
  while (k == 1){
    boostrap <- train_sal(1:n, replace = TRUE, prob = pesos)
    fit <- naivebayes(salary ~ ., data = train_sal[boostrap, -1],
                 control = control)
    k <- length(fit$frame$var)
  }
  flearn <- predict(fit, newdata = test_sal, type = "class")
  ind <- as.numeric(vardep != flearn)
  err <- sum(pesos * ind)
}
train_sal<-as.data.frame(train_sal)
test_sal<-as.data.frame(test_sal)
sal.bagging <- bagging(Salary ~.,data=train_sal,bag = TRUE,mfinal=5,control=naivebayes.control(maxdepth=5, minsplit=15,CP=0))
#Using the pruning option
sal.bagging.pred <- predict.bagging(sal.bagging,newdata=test_sal, newmfinal=3)
sal.bagging.pred$confusion
sal.bagging.pred$error ##0.1610226
#######################Using Boosting
sal.naivebayes <- naivebayes(Salary~.,data=train_sal,maxdepth=5)
sal.naivebayes.pred <- predict(sal.naivebayes,newdata=test_sal,type="class")
tb <- table(sal.naivebayes.pred,test_sal[,14])
error.naivebayes <- 1-(sum(diag(tb))/sum(tb))
tb
error.naivebayes  ###0.1610226
sal.adaboost <- boosting(Salary ~.,data=train_sal[1:30161,],mfinal=3, coeflearn="Zhu",
                         control=naivebayes.control(maxdepth=5))
sal.adaboost.pred <- predict.boosting(sal.adaboost,newdata=test_sal[1:15060,])
sal.adaboost.pred$confusion
sal.adaboost.pred$error   ##0.1953519
#comparing error evolution in training and test set
errorevol(sal.adaboost,newdata=train_sal[1:30161, ])->evol.train
errorevol(sal.adaboost,newdata=test_sal[1:15060, ])->evol.test
plot.errorevol(evol.test,evol.train)


  